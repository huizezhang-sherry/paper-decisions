{
  "hash": "66c4ceacf7e2961f0a8d963014b402eb",
  "result": {
    "engine": "knitr",
    "markdown": "---\nformat: \n  acm-pdf:\n    code-overflow: wrap\nkeep-tex: true\npdf-engine: pdflatex\nbibliography: references.bib\ntitle: \"Dossier: visualizing/ understanding decision choices in data analysis via decision similarity\"\nabstract: \"In data analysis, analysts are expected to clearly communicate the decisions they make, as these choices inform how results are interpreted and compared across studies. Such decisions -- for example, selecting the degree of freedom for a smoothing spline -- are often not systematically studied, since onece an analysis is published, it is done seldom revisited or replicated with alternative choices. In this work, we focus on a body of data analysis studies on the effect of particulate matter on mortality, conducted by researchers worldwide, which naturally provide alteranative analyes of the same question. We automatically extract analytic decisions from the published literature into structured data using Large Language Models (Claude and Gemini). We then proposed a pipeline to calculate paper similarity based on the semantic similarity of these extracted decisions and their reasons, and visualize the results through clustering algorithms. This approach offers an efficient way to study decision-making  practices than traditional interviews. We also provide insights into the use of LLMs for text extraction tasks and the communication of analytic choices in data analysis practice.\"\nnotebook-links: false\nauthor:\n  - name: H. Sherry Zhang\n    email: hsherryzhang@utexas.edu\n    affiliation:\n      name: University of Texas at Austin\n      city: Austin\n      state: Texas\n      country: USA\n  - name: Roger D. Peng\n    affiliation:\n      name: University of Texas at Austin\n      city: Austin\n      state: Texas\n      country: USA\n# acm-specific metadata\nacm-metadata:\n  # comment this out to make submission anonymous\n  anonymous: true\n  # comment this out to build a draft version\n  #final: true\n  # comment this out to specify detailed document options\n  # acmart-options: sigconf, review\n  # acm preamble information\n  copyright-year: 2025\n  acm-year: 2025\n  copyright: acmcopyright\n  doi: XXXXXXX.XXXXXXX\n  conference-acronym: \"CHI'26\"\n  conference-name: CHI Conference on Human Factors in Computing Systems\n  conference-date: Apr 13--17, 2026\n  conference-location: Barcelona, Spain\n  isbn: 978-1-4503-XXXX-X/18/06\n\n  # if present, replaces the list of authors in the page header.\n  #shortauthors: Trovato et al.\n\n  # The code below is generated by the tool at http://dl.acm.org/ccs.cfm.\n  # Please copy and paste the code instead of the example below.\n  ccs: |\n   \\begin{CCSXML}\n   <ccs2012>\n    <concept>\n       <concept_id>10010405.10010497.10010504.10010505</concept_id>\n       <concept_desc>Applied computing~Document analysis</concept_desc>\n       <concept_significance>300</concept_significance>\n       </concept>\n      <concept>\n       <concept_id>10003120.10003121.10003126</concept_id>\n       <concept_desc>Human-centered computing~HCI theory, concepts and models</concept_desc>\n       <concept_significance>500</concept_significance>\n       </concept>\n   </ccs2012>\n   \\end{CCSXML}\n\n   \\ccsdesc[300]{Applied computing~Document analysis}\n   \\ccsdesc[500]{Human-centered computing~HCI theory, concepts and models}\n\n  keywords:\n    - Large language models\n    \n  # if uncommented, this produces a teaser figure\n  #\n  # teaser:\n  #   image: sampleteaser\n  #   caption: figure caption\n  #   description: teaser description\n---\n\n\n::: {.cell .hidden}\n\n```{.r .cell-code .hidden}\nknitr::opts_chunk$set(cache = TRUE, echo = FALSE, message = FALSE, \n                      warning = FALSE, fig.align = \"center\", fig.height = 3)\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.4     v readr     2.1.5\nv forcats   1.0.0     v stringr   1.5.1\nv ggplot2   3.5.2     v tibble    3.2.1\nv lubridate 1.9.4     v tidyr     1.3.1\nv purrr     1.0.4     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(dossier)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nRegistered S3 method overwritten by 'future':\n  method               from      \n  all.equal.connection parallelly\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(ggdendro)\nlibrary(patchwork)\nlibrary(text)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;34mThis is text (version 1.5).\n\u001b[0m\u001b[0;32mNewer versions may have improved functions and updated defaults to reflect current understandings of the state-of-the-art.\u001b[0m\u001b[0;35m\n\nFor more information about the package see www.r-text.org.\u001b[0m\n\u001b[0;34mtextrpp python option is already set, text will use: condaenv = \"textrpp_condaenv\"\u001b[0m\n\u001b[0;32m\nSuccessfully initialized text required python packages.\n\u001b[0m\n\u001b[0;34mPython options: \n type = \"textrpp_condaenv\", \n name = \"textrpp_condaenv\".\u001b[0m\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nload(here::here(\"data/text_sensitivity_decision_df.rda\"))\nload(here::here(\"data/text_sensitivity_df.rda\"))\nload(here::here(\"data/llm_temp_df.rda\"))\nload(here::here(\"data/all_geminis.rda\"))\ngemini_df <- read_csv(here::here(\"data/gemini_df.csv\")) |> as_decision_tbl()\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nRows: 273 Columns: 8\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr (8): paper, variable, type, model, method, parameter, reason, decision\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nclaude_df <- read_csv(here::here(\"data/claude_df.csv\")) |> as_decision_tbl()\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nRows: 360 Columns: 8\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr (8): paper, variable, type, model, method, parameter, reason, decision\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n\n-   Something about \"analysis review\" - Roger thinks it's a better to have a new word for this.\n-   demonstrate - analytically homogeneous - the table won't look like that\n\n# Introduction\n\nDecisions are everywhere in data analysis, from the initial data collection, data pre-processing to the modelling choices. These decisions will impact the final output of the data analysis, which may lead to different conclusions and policy recommendations. When such flexibility can be misused—through practices such as p-hacking, selective reporting, or unjustified analytical adjustments—it can inflate effect sizes or produce misleading results that meet conventional thresholds for statistical significance. They have been demonstrated through many-analysts experiments, where independent teams analyzing the same dataset to answer a pre-defined research question often arrive at markedly different conclusions. These practices not only compromise the validity of individual studies but also threaten the broader credibility of statistical analysis and scientific research as a whole.\n\nMultiple recommendations have been proposed to improve data analysis practices, such as pre-registration and multiverse analysis. Bayesian methods also offer a different paradigm to p-value driven inference for interpreting statistical evidence. Most empirical studies of data analysis practices focus on specially designed and simplified analysis scenarios. While informative, these setups may not adequately capture the complexity of the data analysis with significant policy implications. \\[In practice, studying the data analysis decisions with actual applications is challenging.\\] Analysts may no longer be available for interviews due to job changes, and even when they are, recalling the full set of decisions and thinking process made during the analysis is often infeasible. Moreover, only until the last decades, analysis scripts and reproducible materials were not commonly required by journals for publishing. \\[As a result, it remains challenging to study how analytical decisions are made. \\]\n\nIn this work, we focus on a specific class of air pollution modelling studies that estimate the effect size of particulate matter (PM2.5 or PM10) on mortality, typically using Poisson regression or generalized additive models (GAMs). While individual modelling choices vary, these studies often share a common structure: they adjust for meteorological covariates such as temperature and humidity, apply temporal or spatial treatments, like including lagged variables and may estimate the effect by city or region before combining results. Because these studies investigate similar scientific questions using a shared modelling framework, they form a natural many-analyst setting. This allows us to examine, in a real-world context, the range of analytical decisions made by different researchers addressing the same underlying question.\n\n<!-- This class of studies has significant impact to provide scientific evidence for to guide public policy on setting the National Ambient Air Quality Standards (NAAQS) for air pollutants in the U.S.  -->\n\nIn this work, we develop a structured tabular format to record the analytical decisions made by researchers in the air pollution modelling literature. Using large language models (LLMs), we automate the extraction of these decisions from published papers. This allows us to treat decisions as data – allowing us to track them over time, compare methodology across papers, and query commonly used approaches. We further introduce a workflow to cluster studies based on decision similarity, revealing three distinct groups of papers that reflect the modelling strategies differs in the European and U.S. studies, which offers a new way to visualize the field in the air pollution mortality modelling.\n\nThe contribution of this work includes:\n\n-   A new approach to study data analysis decision choices through automatic extraction of decisions from scientific literature using LLMs,\n\n-   A dataset compiled from 62 papers to study decision-making in air pollution mortality modelling,\n\n-   A pipeline to construct similarities between papers based on decision similarities, and\n\n-   Issues we found from existing data analysis reporting\n\nThe rest of the paper is organized as follows. In @sec-background, we review the background on data analysis decisions. @sec-extract-decisions describes the data structure for recording decisions, the use of large language models to process research papers, and the validation of LLM outputs. In @sec-paper-similarity, we present the method for calculating paper similarity based on decision similarities. @sec-result reports the finding of our analysis, including the clustering of papers according to similarity scores and sensitivity analyses related to LLM providers, prompt engineering, and LLM parameters. Finally, @sec-discussion discusses the implications of our study.\n\n# Related work {#sec-background}\n\n## Decision-making in data analysis\n\nA data analysis is a process of making choices at each step, from the initial data collection to model specification, and post-processing. Each decision represents a branching point where analysts choose a specific path to follow, and the vast number of possible choices analysts can take forms what @gelman2014 describe as the \"garden of forking paths\". While researchers may hope their inferential results are robust to the specific path taken through the garden, in practice, different choices can lead to substantially different conclusions. This has been empirically demonstrated through \"many analyst experiments\", where independent research groups analyze the same dataset to the same answer using their chosen analytic approach. A classic example is @silberzahn2018, where researchers reported an odds ratio from 0.89 to 2.93 for the effect of soccer players’ skin tone on the number of red cards awarded by referees. Similar variability has been observed in structural equation modeling [@sarstedt2024], applied microeconomics [@huntington-klein2021], neuroimaging [@botvinik-nezer2020], and ecology and evolutionary biology [@gould2025].\n\nExamples above have rendered decision-making in data analysis as a subject to study in data science. To collect data on how analysts making decisions during data analysis, researchers have conducted interviews with analysts and researchers on data analysis practices [@kale2019; @alspaugh2019; @liu_understanding_2020], visualization of the decision process through the analytic decision graphics (ADG) [@liu2020]. Recently, @simson2025 describes a participatory approach to decisions choices in fairness ML algorithms. Software tools have also developed to incorporate potential alternatives in the analysis workflow, including the `DeclareDesign` package [@blair2019] and the `multiverse` package [@multiverse]. The `DeclareDesign` package [@blair2019] introduces the MIDA framework for researchers to declare, diagnose, and redesign their analyses to produce a distribution of the statistic of interest, which has been applied in the randomized controlled trial study [@bishop2024]. The `multiverse` package [@multiverse] provides a framework for researchers to systematically explore how different choices affect results and to report the range of plausible outcomes that arise from alternative analytic paths. Other systems have been developed to visualize `multiverse` analysis [@liu2021].\n\n## Visualization on scientific literature\n\nMuch of the work on IEEE visualizing scientific literature focuses on helping researchers stay aware of relevant publications, given the rapidly growing volume of scientific output and the difficulty of navigating it. Systems have been developed to support the discovery of relevant papers, where relevance is typically determined by keywords [@isenberg2017], citation information (e.g. citation list, co-citation) [@chen2006], or combinations with other relevant paper metadata (e.g. author, title) [@bethard2010; @chou2011; @dörk2012; @heimerl2016]. More recent approaches incorporate text-based information from the abstract or sections of the paper to \\[obtain a better similar metric\\]. This includes using topic modelling [@alexander2014], argumentation-based information retrieval [@tbahriti2006], and text embedding [@narechania2022]. While these metadata information and high level text-based information are valuable for discovering relevant papers, for data analysis, researchers need tools that help them *make sense* of the literature rather than simply *finding* it. Capturing the decisions and reasoning expressed during analyses within a similar theme can reveal common practices in the field and guide decisions choices in new applications. With recent advances in Large Language Models (LLMs), it has become possible to automatically extract structured information from unstructured text through prompting. This allows scientific literature to be clustered and visualized using information about the underlying decisions and reasoning made during analysis, providing a basis for studying analysts' decision choices.\n\n# Methods {#sec-extract-decisions}\n\n## Decisions in data analysis {#sec-decisions}\n\nDecisions occur throughout the entire data analysis process -- from the selection of variables and data source, to pre-processing steps to prepare the data for modelling, to the model specification and variable inclusion. In this work, we focus specifically on modelling decisions in the air pollution mortality modelling literature. These include the choice of modelling approach, covariate inclusion and smoothing, and specifications of spatial and temporal structure. Consider the following excerpt from @ostro2006:\n\n> Based on previous findings reported in the literature (e.g., Samet et al. 2000), the basic model included a smoothing spline for time with 7 degrees of freedom (df) per year of data. This number of degrees of freedom controls well for seasonal patterns in mortality and reduces and often eliminates autocorrelation.\n\nThis sentence encode the following components of a decision:\n\n-   **variable**: time\n-   **method**: smoothing spline\n-   **parameter**: degree of freedom (df)\n-   **reason**: Based on previous findings reported in the literature (e.g., Samet et al. 2000); This number of degrees of freedom controls well for seasonal patterns in mortality and reduces and often eliminates autocorrelation.\n-   **decision**: 7 degrees of freedom (df) per year of data\n\nThe decision above is regarding a certain parameter in the statistical method, we categorize this as a \"parameter\" type decisions. Other types of decisions - such as spatial modelling structure or the inclusion of temporal lags - may not include an explicit method or parameter, but still reference a variable and rationale, which we will provide further examples below.\n\nTo record these decisions, we follow the tidy data principle [@wickham2014], where each variable should be in a column, each observation in a row. In our context, each row represents a decision made by the authors of a paper and an analysis often include multiple decisions. To retain the original context of the decision, we extract the original text in the paper, without paraphrase or summarization, from the paper. Below we present an example of how to structure the decisions made in a paper, using the paper by @ostro2006:\n\n| Paper | ID | Model | variable | method | parameter | type | reason | decision |\n|--------|--------|--------|--------|--------|--------|--------|--------|--------|\n| ostro | 1 | Poisson regression | temperature | smoothing spline | degree of freedom | parameter | NA | 3 degree of freedom |\n| ostro | 2 | Poisson regression | temperature | smoothing spline | degree of freedom | temporal | NA | 1-day lag |\n| ostro | 3 | Poisson regression | relative humidity | LOESS | smoothing parameter | parameter | to minimize Akaike's Information Criterion | NA |\n| ostro | 4 | Poisson regression | model | NA | NA | spatial | to account for variation among cities | separate regression models fit in each city |\n\nMost decisions in the published papers are not explicitly stated, this could due to the coherence and conciseness of the writing or authors' decision to include only necessary details. Here, we identify a few common anomalies where decisions may be combined or omit certain fields:\n\n1.  **Authors may combine multiple decisions into a single sentence** for coherence and conciseness of the writing. Consider the following excerpt from @ostro2006:\n\n> Other covariates, such as day of the week and smoothing splines of 1-day lags of average temperature and humidity (each with 3 df), were also included in the model because they may be associated with daily mortality and are likely to vary over time in concert with air pollution levels.\n\nThis sentence contains four decisions: two for temperature (the temporal lag and the smoothing spline parameter) and two for humidity. These decisions should be structured as separate entries.\n\n2.  **The justification does not directly address the decision choice.** In the example above, the stated rationale (\"and are likely to vary over time in concert with air pollution levels\") supports the general inclusion of temporal lags but does not justify the specific choice of 1-day lag over alternatives, such as 2-day average of lags 0 and 1 (lag01) and single-day lag of 2 days (lag2). As such, the reason field should be recorded as NA.\n\n3.  **Some decisions may be omitted because they are data-driven**. For instance, @katsouyanni2001 states:\n\n> The inclusion of lagged weather variables and the choice of smoothing parameters for all of the weather variables were done by minimizing Akaike’s information criterion.\n\nIn this case, while the method of selection (minimizing AIC) is specified, the actual degree of freedom used is not. Such data-driven decisions may be recorded with \"NA\" in the decision field, but the reason field should still be recorded as \"by minimizing Akaike’s information criterion\"\n\n4.  **Information required to interpret the decision may be distributed across multiple sections**. In the previous example, \"weather variables\" refers to mean temperature and relative humidity, as defined earlier in the text. This requires cross-referencing across sections to identify the correct variables associated with each modeling choice.\n\n<!-- | Paper | ID | Model | variable | method | parameter | type | reason | decision | -->\n\n<!-- |-----|--|--------|--------|--------|--------|--------|--------|--------| -->\n\n<!-- | ostro | xx | Poisson regression | temperature | smoothing spline | degree of freedom | parameter | NA | 3 df | -->\n\n<!-- | ostro | xx | Poisson regression | temperature | NA | NA | temporal | NA | 1-day lag | -->\n\n<!-- | ostro | xx | Poisson regression | relative humidity | smoothing spline | degree of freedom | parameter | NA | 4 df | -->\n\n<!-- | ostro | xx | Poisson regression | relative humidity | NA | NA | temporal | NA | 1-day lag | -->\n\n<!-- | katsouyanni2001 | xx | generalized additive models (GAM) Poisson regression | mean temperature | smoothing spline | degree of freedom | parameter | by minimizing Akaike’s information criterion | NA | -->\n\n<!-- | katsouyanni2001 | xx | generalized additive models (GAM)  Poisson regression | relative humidity | smoothing spline | degree of freedom | parameter | by minimizing Akaike’s information criterion | NA | -->\n\n## Automatic reading of literature with LLMs\n\n**TODO**: Prompt engineering: these models may paraphrase or hallucinate unless explicitly told not to since it is generative in nature based on the predicted probability of the next word from the text and the instruction\n\n**TODO**: The Prompt Report: A Systematic Survey of Prompt Engineering Techniques <https://arxiv.org/pdf/2406.06608>\n\nWhile decisions can be extracted manually from the literature, this process is labor-intensive and time-consuming. Recent advances in Large Language Models (LLMs) have demonstrated potential for automating the extraction of structured information from unstructured text \\[ref\\]. In this work, we use LLMs to automatically identify decisions made by authors during their data analysis processes.\n\nText recognition from PDF document relies on Optical Character Recognition (OCR) to convert scanned images into machine-readable text -- capability currently offered by Antropic Claude and Google Gemini. We instruct the LLM to generate a markdown file containing a JSON block that records extracted decisions, which can then be read into statistical software for further analysis. The exact prompt feed to the LLM is provided in the Appendix. The `ellmer` package [@ellmer] in R is used to connect to the Gemini and Claude API, providing the PDF attachment and the prompt in a markdown file as inputs.\n\n\n\n````{}\n# Task\n\nConsider yourself as an applied statistician and you will read a PDF file to extract the decisions made in the data analysis. Your output should contain a JSON code block under the top-level key \"decisions\". Each item in \"decisions\" should be a dictionary with the following fields:\n\n- `model`: the main model used to model mortality vs. air pollution (e.g., \"generalized additive model\", \"distributed lag model\"). Should be one model per paper.\n- `variable`: the variable the statistical method is applied to.\n- `method`: standard statistical method applied, for example, \"LOESS\", \"smoothing spline\", and \"natural spline\". If the `type` is \"spatial\" or \"temporal\", write \"NA\". There may be multiple methods discussed in the paper. Only extract the method that is actually used on the variable.\n- `parameter`: the parameter name of the statistical method discussed, for example, \"degrees of freedom\", and \"number of knots\". If the `type` is \"spatial\" or \"temporal\", write \"NA\". Do not use the value of the parameter, for example, \"3 df\". \n- `type`: one of \"parameter\", \"spatial\", or \"temporal\", indicating the nature of the decision. \n- `reason`: the reason for the decision made. If none is given, write \"NA\".\n- `decision`: the decision made regarding the parameter, spatial, or temporal aspect. If not specified, write \"NA\".\n- `reference`: if the reason for the decision has any reference, find the corresponding reference in the reference section and write the reference in the following format: abc, where a is the last name of first author (without accent and all lower letters), b is the year in four digit format, and c is the first word of the title, excluding a/an/the, e.g. braga2001lag. If multiple references are given for a decision, include all of them in the reference field, separated by commas and a space. Do not stop at the first reference. Do not split into multiple rows\n\nAn example looks like the following:\n\n````json\n{\n  \"decisions\": [\n    {\n      \"model\": \"generalized additive model\",\n      \"variable\": \"PM2.5\",\n      \"method\": \"smoothing spline\",\n      \"parameter\": \"smoothing parameter\",\n      \"type\": \"parameter\",\n      \"reason\": \"based on published litearture\",\n      \"decision\": \"5 df\",\n      \"reference\": \"smith2005trend\"\n    }\n  ]\n}\n````\n\n## Rules\n\n* Some decisions may require linking information across sentences and/or paragraphs to identify the correct variable. Example: \n  * Text: if a paragraph states \"... model adjusted for overdispersion, to estimate associations between day-to-day variations in pollutant concentrations (lag 0–5) and day-to-day variations in hospital admission counts for three health outcomes separately. A basic model without pollutants was built first, ....\", Followed by the next paragraph: \"After assessing the effects of single day concentrations (lags 0–5), ...\"\n  * Guidance: The temporal decision (\"lag 0-5\"\") refers to pollutant concentrations, not the model. \n\n* If a sentence includes multiple decisions that vary by outcome or variable, each decision should be treated and recorded separately.\n  * Example 1: \n    * Text: \"resulting in a 4-day pollutant average (lag 0–3) for CVD, a 5-day average (lag 0–4) for RD, and a 6-day average (lag 0–5) for asthma\" \n    * Output: three separate decisions of type \"temporal\"\" (variable/ decision): 1) CVD/ 4-day average (lag 0–3), 2) RD/ 5-day average (lag 0–4), 3) Asthma/ 6-day average (lag 0–5)\n  * Example 2:\n    * Text: “smoothing splines of one-day lags of humidity [each with 3 degrees of freedom (df)]”\n    * Output:\n      * Decision 1: variable: \"humidity\", type: \"temporal\", decision: \"one-day lag\"\n      * Decision 2: variable: \"humidity\", type: \"parameter\", decision: \"3 df\"\n  * Example 3:\n    * Text: \"three- day averaged temperature and dew point temperature with a natural cubic spline with three d.f..\"\n    * Output:\n      * Decision 1: variable: \"temperature\", method: \"NA\", type: \"temporal\", decision: \"3-day averaged\"\n      * Decision 2: variable: \"dew point temperature\", method: \"NA\", type: \"temporal\", decision: \"3-day averaged\"\n      * Decision 3: variable: \"temperature\", method: \"natural cubic spline\" , type: \"parameter\", decision: \"3 df\"\n      * Decision 4: variable: \"dew point temperature\", method: \"natural cubic spline\", type: \"parameter\", decision: \"3 df\"\n\n* Temporal terms may indicate parameter choices: words like “monthly,” “weekly,” or “daily” may appear in sentences, but they do not always imply temporal decisions. Sometimes they describe how a smoothing function is applied, which is a parameter decision. Example: \n  * Text: \"We set time-based knots at monthly midpoints.\"\n  * Interpretation: This describes a spline function applied to time, using 12 knots (one per month) \n  * Output: This is a *parameter* decision, not a temporal one. \n\n* Please use cognitive reasoning to determine whether the extracted reason is *specific* to the decision made. If the reason is general and doesn't justify the particular choice, write \"NA\". Example: \n  * Text: \"To control for weather variables, the 14-day lagged moving average (including concurrent day and previous 13 days) of temperature, dew point temperature, and barometric pressure (as both linear and quadratic terms) were included in the conditional logistic regression models.\", \n  * Decision: \"14-day lagged values\" \n  * Extracted reason: \"to control for weather variables\" \n  * Output: \"NA\" because the reason is general to why the weather variables are included and do not justify why this temporal decision of 14-day lag is chosen\n\n* Only include rows where a clear decision is made on a parameter, spatial, or temporal aspect of the modeling. For ambiguous or vague decisions (e.g., \"not below 2 months\"), do not record a row.\n\n* Do NOT include decisions about inclusion of variables, for example, reasons as \"to filter out cyclical patterns\" and decision as \"include day-of-the-week variable.\n\n* A paper may contain multiple models; label them precisely (e.g., \"generalized additive Poisson regression\", \"lag distributed model\").\n\n* Convert numbers written in words to numerals. For example, rewrite \"one-day lag\" as \"1-day lag\". Apply this consistently across all entries.\n````\n\n\n\n## Review the LLM output\n\n-   **TODO** something about result validation of LLM output: We also observe data quality with the extraction: for example in @lee2006, the variable recorded is \"smoothing parameter\". Authors are unclear about the delivery Specify how much of validation and review has been done.\n\nThe shiny app is designed to provide users a visual interface to review and edit the decisions extracted by the LLM from the literature. The app allows three actions from the users: 1) *overwrite* -- modify the content of a particular cell, equivalently `dplyr::mutate(xxx = ifelse(CONDITION, \"yyy\" , xxx))`, 2) *delete* -- remove a particular cell, `dplyr::filter(!(CONDITION))`, and 3) *add* -- manually enter a decision, `dplyr::bind_rows()`. @fig-shiny illustrates the *overwrite* action in the Shiny application, where users interactively filter the data and preview the rows affected by their edits—in this case, changing the model entry from \"generalized additive Poisson time series regression\" to the less verbose \"Poisson regression\". Upon confirmation, the corresponding `tidyverse` code is generated, and users can download the edited table and incorporate the code into their R script.\n\n\n::: {#cell-fig-shiny .cell layout-align=\"center\"}\n\n```{.r .cell-code .hidden}\nknitr::include_graphics(\"figures/shiny.png\")\n```\n\n::: {.cell-output-display}\n![The Shiny application interface for editting Large Language Model (LLM)-generated decisions (overwrite, delete, and add). (1) the default interface after loading the input CSV file. (2) The table view will update interactively upon the user-defined filter condition -- expressed using `dplyr::filter()` syntax (e.g., `paper == anderson2008size\"`), (3) The user edits the `model` column to \"Poisson regression\" and applies the change by clicking the Apply changes button. The table view updates to reflect the changes (4) After clicking the Confirm button, the corresponding `tidyverse` code is generated, and the table view returns to its original unfiltered view. The edited data can be downloaded by clicking the Download CSV button.](figures/shiny.png){#fig-shiny fig-align='center' fig-pos='H' width=100%}\n:::\n:::\n\n\n# Calculating paper similarity {#sec-paper-similarity}\n\nOnce the decisions have been extracted and validated, this opens up a structured data for analyzing these information. For example, we can compare whether author's choices at different times changes, or across decisions varies at different regions. In this section, we present a method to calculate paper similarity based on the decisions shared in the paper pairs. The goal is to construct a distance metric based on similarity of the decision choice among papers that could be further used for clustering paper based on choices made by different authors in the literature. An overview of the method is illustrated in @fig-similarity-diag.\n\n\n::: {#cell-fig-similarity-diag .cell layout-align=\"center\"}\n\n```{.r .cell-code .hidden}\nknitr::include_graphics(\"figures/similarity-diag.png\")\n```\n\n::: {.cell-output-display}\n![Workflow for calculating paper similarity based on decision choices: (1) standardize variable names, (2) identify most frequent variable-type decisions across all papers, (3) identify papers with at least x identified decisions, (4) calculate decisions similarity score on the *decision* and *reason* fields using transformer language models, e.g. BERT, (5) calculate paper similarity score based on aggregating decision similarity scores.](figures/similarity-diag.png){#fig-similarity-diag fig-align='center' fig-pos='H' width=100%}\n:::\n:::\n\n\n-   **TODO** some discussion on what it means by for two papers to be similar based on decisions.\n\nThe calculation of paper similarity is based on the similarity of decisions shared by each paper pair. A decision comparable in two papers are the ones that share the same variable and type, e.g. temperature and parameter (a decisions on the choosing the statistical method *parameter* for the *temperature* variable), or humidity and temporal (any *temporal* treatment, e.g. choice of lag value for the *humidity* variable). While many decisions share a similar variable, different authors may refer to them with slightly different names, such as \"mean temperature\" and \"average temperature\", hence variable names are first standardized to a common set of variable names. For example, \"mean temperature\" and \"average temperature\" are both standardized to \"temperature\". Notice that \"dewpoint temperature\" is standardized into \"humidity\" since it is a proxy of temperature to achieve a relative humidity (RH) of 100%. For literature with a common theme, there is usually a set of variables that shared by most papers and additional variables are justified in individual research. For our air pollution mortality modelling literature, we standardize the following variable names:\n\n-   **temperature**: \"mean temperature\", \"average temperature\", \"temperature\", \"air temperature\", \"ambient temperature\"\n-   **humidity**: \"dewpoint temperature\" and its hyphenated variants, relative humidity\", \"humidity\"\n-   **PM**: \"pollutant\", \"pollution\", \"particulate matter\", \"particulate\", \"PM10\", \"PM2.5\"\n-   **time**: \"date\", \"time\", \"trends\", \"trend\"\n\nDepending on the specific pairs, papers have varied number of decisions that can be compared and aggregated. While paper similarities can be computed for all paper pairs, using the similarity of one or two pair of decisions to represent paper similarity is less ideal. Hence, before calculating the text similarity of decisions, we also include two optional steps to identify and subset the most frequent decisions across papers, and to retain only papers that report more than a certain number of frequent decisions. Research questions in different fields may have different levels of homogeneity, depending on the maturity of the field and for air pollution mortality modelling, it is helpful to focus on decisions and papers that share a substantial number of decisions.\n\nTo assign numerical value for the similarity of reason, we use a transformer language model, such as BERT, to measure the semantic text similarity between the decision itself and its justification. The decision similarity is calculated by comparing the *decision* and *reason* fields of the decisions in each paper pair. To obtain paper similarity, we average the decision similarities across all decisions in each paper pair and other method can be customized for aggregation. The resulting paper similarity score can be used as a distance matrix to cluster papers based on their decision choices to understand the common practices in the investigated literature.\n\n# Results {#sec-result}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code .hidden}\ndt <- gemini_df |> \n  mutate(decision = is.na(decision), reason = is.na(reason), .keep = \"used\" ) \n  \ndt_tbl <- table(dt)\nrownames(dt_tbl)  <- c(\"Non-missing\", \"Missing\")\npct <- round(prop.table(dt_tbl) * 100, 1)\nlab <- matrix(\n  paste0(dt_tbl, \" (\", pct, \"%)\"),\n  nrow = nrow(dt_tbl),\n  dimnames = dimnames(dt_tbl)\n)\n```\n:::\n\n\nFrom the 57 studies examining the effect of particulate matters ($\\text{PM}_{10}$ and $\\text{PM}_{2.5}$) on mortality, we focus on the baseline model reported in each paper, excluding secondary models (e.g. lag-distributed models) and sensitivity analysis. We also exclude decisions on other pollutants, such as nitrogen dioxide ($\\text{NO}_2$). This yields 273 decisions extracted using Gemini, averaging approximately 5 decisions per paper. @tbl-missing-decisions summarizes the missingness of the decisions and reason. While most papers report their decision choices (e.g. use of five degree of freedom), 57% of decisions lack a stated rationale for the choice. @tbl-most-common-decisions lists teh eight most frequently reported decision: parameter and temporal choice for time, PM, temperature, and humidity. \n\n\n::: {#tbl-missing-decisions .cell layout-align=\"center\" tbl-cap='Missingness of decision and reason fields in the Gemini-extracted decisions. Most decisions report the choice (35.5 + 57.1 = 92%), but 57.1% lacks a stated reason.'}\n\n```{.r .cell-code .hidden}\nlab |> knitr::kable(\n  col.names = c(\"Decision\", \"Reason\", \"Non-missing\", \"Missing\"),\n  format = \"latex\", booktabs = TRUE) |> \n   kableExtra::add_header_above(c(\"\", \"Decision\" = 2), \n                    escape = FALSE) \n```\n\n::: {.cell-output-display}\n\n\\begin{tabular}{lll}\n\\toprule\n\\multicolumn{1}{c}{} & \\multicolumn{2}{c}{Decision} \\\\\n\\cmidrule(l{3pt}r{3pt}){2-3}\nReason & Non-missing & Missing\\\\\n\\midrule\nNon-missing & 97 (35.5\\%) & 16 (5.9\\%)\\\\\nMissing & 156 (57.1\\%) & 4 (1.5\\%)\\\\\n\\bottomrule\n\\end{tabular}\n\n\n:::\n:::\n\n\n\n\n::: {#tbl-most-common-decisions .cell layout-align=\"center\" tbl-cap='Count of variable-type decisions in the Gemini-extracted decisions. The most commonly reported decision are the parameter choices and temporal lags for for time, PM, temperature, and humidity.'}\n\n```{.r .cell-code .hidden}\ncount_variable_type(gemini_df) |> head(8) |> \n  knitr::kable(col.names = c(\"Variable\", \"Type\", \"Count\"),)\n```\n\n::: {.cell-output-display}\n\n\n|Variable    |Type      | Count|\n|:-----------|:---------|-----:|\n|PM          |temporal  |    56|\n|time        |parameter |    45|\n|temperature |parameter |    37|\n|humidity    |parameter |    26|\n|temperature |temporal  |    25|\n|humidity    |temporal  |    20|\n|PM          |parameter |     8|\n|mortality   |temporal  |     4|\n\n\n:::\n:::\n\n\n\n@tbl-humidity-temperature-decisions reports the parameter-related decisions captured in the literature. They refer to the number of knots or degree of freedom for spline methods (natural and smoothing spline) applied to variable time, humidity and temperature. For consistency, all values have been converted to a  *per year* scale. The selection of knot for natural spline has less variation than the degree of freedom choices for smoothing spline. Choices for temperature and humidity tend to be close, given they are both weather related variables, while the choices for time are more varied inherently. This tabulation offers a reference set for potential options for future studies and help to identify anomalies and special treatment in practice. Notable example includes the use of 7.7 degree of freedom in @castillejos2000, and highly flexible choices of 30 and 100 in @moolgavkar2000 and @moolgavkar2003, respectively. While most papers choice to report the smoothing parameter as a constant value, @schwartz2000 specifies it as a proportion of the data (\"5% of the data\" and \"5% of the data\").\n\nFor temporal decisions, after an initial review, we observed that decisions are still highly varied. The decisions can be divided into two groups: multi-day lags include expressions such as \"6-day average\", \"3-d moving average\", \"mean of lags 0+1\", and \"cumulative lags, mean 0+1+2\", and single-day lags include \"lagged exposure up to 6 days\", \"lag days from 0 to 5\" among others. To standardize these entries, we applied a secondary LLM process (claude-3-7-sonnet-latest) and converted them into a consistent format: `multi-day: lag [start]-[end]` and `single-day: lag [start], … lag [end]`. @tbl-temporal-decisions summarizes the temporal lag choices for PM, temperature, and humidity. Both single and multiple day lags are generally considered up to five days prior (lag 5). [TODO: check multi-day starts from one].\n\n\n::: {#tbl-humidity-temperature-decisions .cell layout-align=\"center\" tbl-cap='Options captured for parameter choices for time, humidity, and temperature variables in the Gemini-extracted decisions. The choices for natural spline knots are generally less varied than the degree of freedom choices for smoothing spline. Choices for temperature and humidity tend to be close, given they are both weather related variables, while the choices for time are more varied inherently.'}\n\n```{.r .cell-code .hidden}\nvar_method <- gemini_df |> \n  filter(type == \"parameter\", \n         variable %in% c(\"humidity\", \"temperature\", \"time\"),\n         method %in% c(\"smoothing spline\", \"natural spline\")) |> \n  mutate(decision = str_remove(decision, \" knots| df\"),\n          decision = str_replace(decision, \" or\", \",\")) |> \n  separate_longer_delim(decision, delim = c(\"; \")) |> \n  filter(!is.na(decision), !decision %in% c(\"smooth function\")) |> \n  mutate(id = row_number()) |> \n  select(paper, variable, method, decision)\n\nvar_method_df <- var_method |>\n  filter(paper != \"schwartz\") |> \n  mutate(decision = parse_number(decision)) |> \n  distinct(variable, method, decision) |> \n  arrange(variable, method, decision) |> \n  mutate(decision = as.character(decision)) |> \n  bind_rows(var_method |> \n              filter(paper == \"schwartz\") |> \n              mutate(decision = str_remove(decision, \"in each neighborhood\")) |> \n              select(-paper) \n            ) \n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: There was 1 warning in `mutate()`.\ni In argument: `decision = parse_number(decision)`.\nCaused by warning:\n! 1 parsing failure.\nrow col expected                                                                    actual\n 21  -- a number df which minimizes the absolute value of the sum of PACF of the residuals\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nvar_method_df |>\n   mutate(method == ifelse(method == \"natural spline\", \"Natural spline (knot)\", \"Smoothing spline (df)\")) |> \n  group_by(method, variable) |> \n  summarize(decision = paste0(decision, collapse = \", \")) |> \n  knitr::kable(col.names = c(\"Method\", \"Variable\", \"Decision\")) \n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n`summarise()` has grouped output by 'method'. You can override using the\n`.groups` argument.\n```\n\n\n:::\n\n::: {.cell-output-display}\n\n\n|Method           |Variable    |Decision                                                         |\n|:----------------|:-----------|:----------------------------------------------------------------|\n|natural spline   |humidity    |3, 4                                                             |\n|natural spline   |temperature |3, 4, 6                                                          |\n|natural spline   |time        |1, 3, 4, 6, 7, 8, 12                                             |\n|smoothing spline |humidity    |2, 3, 4, 6, 8, 50% of the data                                   |\n|smoothing spline |temperature |2, 3, 4, 6, 8, 50% of the data                                   |\n|smoothing spline |time        |1, 3, 4, 5, 6, 7, 7.7, 8, 9, 10, 12, 30, 100, NA, 5% of the data |\n\n\n:::\n:::\n\n\n\n\n::: {#tbl-temporal-decisions .cell layout-align=\"center\" tbl-cap='Options captured for temporal lag choices for PM, temperature, and humidity variables in the Gemini-extracted decisions. Both single-day lags and multi-day average lags are commonly used, generally considering up to five days prior (lag 5).'}\n\n```{.r .cell-code .hidden}\ntemporal_lags <- gemini_df |> \n  filter(type == \"temporal\") |> \n  distinct(variable, decision) |>\n  arrange(variable, decision) |>\n  mutate(decision = as.character(decision)) |> \n  filter(variable %in% c(\"PM\", \"temperature\", \"humidity\")) |> \n  mutate(type = ifelse(str_detect(decision, \"multi-day\"), \"multi-day average\", \"single-day lag\"),\n         days = ifelse(type == \"multi-day average\", \n                       str_remove(decision, \"multi-day \\\\: lag \"), \n                       str_remove(decision, \"single-day \\\\: \"))) |>\n  group_by(type, variable) |>\n  separate_longer_delim(days, delim = \", \") |> \n  filter(!days %in% c(\"1-1\", \"0-0\")) |> \n  distinct(variable, type, days) |>\n  summarize(decision = paste0(days, collapse = \", \")) |> \n  ungroup()\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n`summarise()` has grouped output by 'type'. You can override using the\n`.groups` argument.\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\ntemporal_lags |> \n  knitr::kable(col.names = c(\"Lag type\", \"Variable\", \"Decision\")) \n```\n\n::: {.cell-output-display}\n\n\n|Lag type          |Variable    |Decision                                               |\n|:-----------------|:-----------|:------------------------------------------------------|\n|multi-day average |PM          |0-1, 0-2, 0-3, 0-4, 0-5, 0-7, 1-0, 1-5                 |\n|multi-day average |humidity    |0-1, 0-2, 0-3, 0-5, 1-3, 1-5                           |\n|multi-day average |temperature |0-1, 0-2, 0-3, 0-5, 0-7, 1-3                           |\n|single-day lag    |PM          |lag 0, lag 1, lag 2, lag 3, lag 4, lag 5               |\n|single-day lag    |humidity    |lag 0, lag 1, lag 2, lag 3, lag 4, lag 5, lag 6, lag 7 |\n|single-day lag    |temperature |lag 0, lag 1, lag 2, lag 3, lag 4, lag 5               |\n\n\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code .hidden}\n#count_variable_type(gemini_df)\ndf <- gemini_df |> filter_var_type(n = 6)\n#count_paper_decisions(df) \n# paper_df <- df |> filter_papers(n_value = 3)\n# count_paper_pair_decisions(paper_df) \n# paper_df$paper |> unique()\n\ngood_pp <- gemini_df |> count(paper) |> filter(n >= 3) |> pull(paper)\npaper_df <- df |> filter(paper %in% good_pp)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code .hidden}\nembed_df <- paper_df |> compute_text_embed()\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;34mProcessing batch 1/4\n\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;32mCompleted layers output for texts (variable: 1/1, duration: 6.548408 secs).\n\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;32mCompleted layers aggregation for word_type_embeddings. \n\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;34mCompleted layers aggregation (variable 1/1, duration: 6.560102 secs).\n\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;34mCompleted layers aggregation (variable 1/1, duration: 6.872855 secs).\n\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;32mMinutes from start:  0.34\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;30mEstimated embedding time left = 1.02 minutes\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;34mProcessing batch 2/4\n\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;33mWarning: non-ascii characters were found in: texts 47; texts 51 Many large laguage models cannot handle them. \n\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;32mTo examine thise text cases use the textNonASCII() function. \n\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;32mNon-ASCII characters has been removed. \n\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;32mCompleted layers output for texts (variable: 1/1, duration: 6.441278 secs).\n\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;32mCompleted layers aggregation for word_type_embeddings. \n\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;34mCompleted layers aggregation (variable 1/1, duration: 7.601204 secs).\n\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;34mCompleted layers aggregation (variable 1/1, duration: 7.866135 secs).\n\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;32mMinutes from start:  0.71\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;30mEstimated embedding time left = 0.71 minutes\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;34mProcessing batch 3/4\n\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;32mCompleted layers output for texts (variable: 1/1, duration: 6.426575 secs).\n\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;32mCompleted layers aggregation for word_type_embeddings. \n\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;34mCompleted layers aggregation (variable 1/1, duration: 6.460197 secs).\n\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;34mCompleted layers aggregation (variable 1/1, duration: 6.660898 secs).\n\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;32mMinutes from start:  1.042\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;30mEstimated embedding time left = 0.347333333333333 minutes\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;34mProcessing batch 4/4\n\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;33mWarning: non-ascii characters were found in: texts 24; texts 26; texts 28 Many large laguage models cannot handle them. \n\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;32mTo examine thise text cases use the textNonASCII() function. \n\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;32mNon-ASCII characters has been removed. \n\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;32mCompleted layers output for texts (variable: 1/1, duration: 4.455306 secs).\n\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;32mCompleted layers aggregation for word_type_embeddings. \n\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;34mCompleted layers aggregation (variable 1/1, duration: 3.600048 secs).\n\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;34mCompleted layers aggregation (variable 1/1, duration: 3.911947 secs).\n\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;32mMinutes from start:  1.247\u001b[0m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\u001b[0;30mEstimated embedding time left = 0 minutes\u001b[0m\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\ndistance_decision_df <- calc_decision_similarity(paper_df, embed = embed_df)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating >------------------------------    1% | ETA:  3m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating =>-----------------------------    2% | ETA:  3m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating =>-----------------------------    3% | ETA:  4m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating =>-----------------------------    4% | ETA:  4m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ==>----------------------------    5% | ETA:  4m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ==>----------------------------    7% | ETA:  4m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ==>----------------------------    8% | ETA:  4m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ===>---------------------------   10% | ETA:  3m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ====>--------------------------   12% | ETA:  3m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating =====>-------------------------   16% | ETA:  3m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating =====>-------------------------   17% | ETA:  2m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating =====>-------------------------   18% | ETA:  3m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ======>------------------------   19% | ETA:  3m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ======>------------------------   20% | ETA:  3m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ======>------------------------   21% | ETA:  3m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating =======>-----------------------   22% | ETA:  3m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating =======>-----------------------   24% | ETA:  3m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ========>----------------------   26% | ETA:  2m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating =========>---------------------   28% | ETA:  2m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating =========>---------------------   30% | ETA:  2m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ==========>--------------------   32% | ETA:  2m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ==========>--------------------   33% | ETA:  2m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ==========>--------------------   34% | ETA:  2m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ===========>-------------------   35% | ETA:  2m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ===========>-------------------   37% | ETA:  2m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ===========>-------------------   38% | ETA:  2m\nCalculating ===========>-------------------   38% | ETA:  2m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ============>------------------   39% | ETA:  2m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating =============>-----------------   43% | ETA:  2m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating =============>-----------------   44% | ETA:  2m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating =============>-----------------   45% | ETA:  2m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ==============>----------------   46% | ETA:  2m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ==============>----------------   48% | ETA:  2m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ===============>---------------   49% | ETA:  2m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ===============>---------------   51% | ETA:  2m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ================>--------------   52% | ETA:  2m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ================>--------------   53% | ETA:  2m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ================>--------------   54% | ETA:  2m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating =================>-------------   55% | ETA:  2m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating =================>-------------   57% | ETA:  1m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating =================>-------------   58% | ETA:  1m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ==================>------------   59% | ETA:  1m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ==================>------------   60% | ETA:  1m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ==================>------------   61% | ETA:  1m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ===================>-----------   62% | ETA:  1m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ===================>-----------   65% | ETA:  1m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ====================>----------   66% | ETA:  1m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ====================>----------   67% | ETA:  1m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating =====================>---------   70% | ETA:  1m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating =====================>---------   71% | ETA:  1m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ======================>--------   72% | ETA:  1m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ======================>--------   73% | ETA:  1m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ======================>--------   74% | ETA:  1m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating =======================>-------   76% | ETA:  1m\nCalculating =======================>-------   76% | ETA:  1m\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating =======================>-------   77% | ETA: 49s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating =======================>-------   78% | ETA: 48s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ========================>------   79% | ETA: 47s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ========================>------   80% | ETA: 45s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ========================>------   80% | ETA: 44s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ========================>------   81% | ETA: 41s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating =========================>-----   82% | ETA: 39s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating =========================>-----   84% | ETA: 37s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ==========================>----   85% | ETA: 33s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ==========================>----   86% | ETA: 31s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ==========================>----   87% | ETA: 29s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ==========================>----   88% | ETA: 27s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ===========================>---   89% | ETA: 25s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ===========================>---   91% | ETA: 21s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ===========================>---   91% | ETA: 20s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ============================>--   92% | ETA: 17s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ============================>--   94% | ETA: 13s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating =============================>-   96% | ETA:  9s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating =============================>-   97% | ETA:  6s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ==============================>  100% | ETA:  1s\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nCalculating ==============================>  100% | ETA:  0s\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\ndistance_df <- distance_decision_df |> calc_paper_similarity()\n```\n:::\n\n\n\n::: {#cell-fig-cluster-paper-1 .cell layout-align=\"center\"}\n\n```{.r .cell-code .hidden}\nget_most_common_method <- function(df, cols = c(\"time_parameter_method\", \n                                                \"humidity_parameter_method\", \n                                                \"temperature_parameter_method\")) {\n  df %>%\n    rowwise() %>%\n    mutate(method = {\n      vals <- c_across(all_of(cols))\n      vals <- vals[!is.na(vals)]\n      if (length(vals) == 0) NA_character_\n      else names(sort(table(vals), decreasing = TRUE))[1]\n    }) %>%\n    ungroup() |> \n    select(paper, method)\n}\n\nmethod_df <- paper_df |> pivot_decision_tbl_wider() |> get_most_common_method() \n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: Values from `decision`, `method` and `reason` are not uniquely identified;\noutput will contain list-cols.\n* Use `values_fn = list` to suppress this warning.\n* Use `values_fn = {summary_fun}` to summarise duplicates.\n* Use the following dplyr code to identify duplicates.\n  {data} |>\n  dplyr::summarise(n = dplyr::n(), .by = c(paper, model, variable, type)) |>\n  dplyr::filter(n > 1L)\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nbad <- method_df |>\n  filter(!method %in% c(\"LOESS\", \"natural spline\", \"smoothing spline\")) |>\n  pull(paper)\ndistance_df <- distance_df |> filter(!paper1 %in% bad & !paper2 %in% bad)\nmethod_df <- method_df |> filter(!paper %in% bad)\n\ndist_m <- to_dist_mtx(distance_df)\nhmod <- hclust(dist_m, \"ave\")\nddata <- dendro_data(hmod)\nddata$labels <- ddata$labels |> left_join(method_df, by = c(\"label\" = \"paper\"))\np2 <- ggplot() +\n  geom_segment(data = segment(ddata), aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_text(data = ddata$labels, \n            aes(x = x, y = y, label = label, color = method, hjust = 0), \n            size = 3) +\n  scale_y_reverse(expand = c(0.2, 0)) + \n  scale_color_brewer(palette = \"Dark2\") + \n  coord_flip() +\n  theme_void() + \n  theme(legend.position = 'bottom')\n  \n\nmds_df <- run_mds(distance_df) |> left_join(method_df, by = c(\"paper\" = \"paper\"))\n\np3 <- mds_df |> ggplot(aes(x = V1, y = V2)) + \n  ggrepel::geom_label_repel(aes(label = paper, color = method)) + \n  scale_color_brewer(palette = \"Dark2\") + \n  theme_bw() + \n  theme(aspect.ratio = 1)  + \n  theme(legend.position = \"none\")\np2\n```\n\n::: {.cell-output-display}\n![The dendrogram (left) and multi-dimensional scaling (MDS) (right) based on paper similarity distance for 62 air pollution mortality modelling literature. The papers are colored by the most common smoothing method used. The MDS reveals the three distinct groups of papers. This grouping corresponds to the modelling strategies differ in the European and U.S. studies, documented in ALPHENA.](index_files/figure-pdf/fig-cluster-paper-1-1.pdf){#fig-cluster-paper-1 fig-align='center' fig-pos='H'}\n:::\n:::\n\n\n\n::: {#cell-fig-cluster-paper .cell layout-align=\"center\"}\n\n```{.r .cell-code .hidden}\n#(p2 | p3) + plot_layout(widths = c(1, 2))\np3 \n```\n\n::: {.cell-output-display}\n![The dendrogram (left) and multi-dimensional scaling (MDS) (right) based on paper similarity distance for 62 air pollution mortality modelling literature. The papers are colored by the most common smoothing method used. The MDS reveals the three distinct groups of papers. This grouping corresponds to the modelling strategies differ in the European and U.S. studies, documented in ALPHENA.](index_files/figure-pdf/fig-cluster-paper-1.pdf){#fig-cluster-paper fig-align='center' fig-pos='H'}\n:::\n:::\n\n\nFor computing the decision similarity score, we include the first 6 most common variable-type decisions as suggested in @tbl-most-common-decisions. @fig-cluster-paper shows the clustering of the 50 papers based on the decision similarity scores. The dendrogram is generated using hierarchical clustering, and the labels are colored according to the most common smoothing method used in each paper. The clustering reveals three distinct groups of papers, which reflect the modelling strategies differ in the European (LOESS) and U.S. (...) studies \\[more on the APHENA\\]. \n\n\n\n# Sensitivity analysis {#sec-sensitivity}\n\nIn this section, we examine the reproducibility for using LLMs for text extraction tasks in @sec-llm-reproducibility, discrepancies between different LLM models: Gemini (`gemini-2.0-flash`) and Claude (`claude-3-7-sonnet-latest`) in @sec-llm-models, and the sensitivity of our paper similarity calculation pipeline to the choice of text model used for computing decision similarity scores in @sec-text-model.\n\n## LLM reproducibility {#sec-llm-reproducibility}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code .hidden}\nall_geminis <- list.files(here::here(\"data/gemini\"), full.names = TRUE) |>\n  purrr::map_dfr( ~ .x |> as_decision_tbl() |> arrange(variable)) |>\n  mutate(id = str_remove(paper, \"-gemini-[0-9]+\"),\n         reason = ifelse(reason == \"NA\", NA, reason ),\n         decision = ifelse(decision == \"NA\", NA, decision ),\n         ) |>\n  mutate(\n    reason = str_replace_all(reason, \"/|,|-\", \"\"),\n    decision = str_replace_all(decision, \"/|,|-\", \"\"),\n    reason = ifelse(!is.na(reason), \n                    paste0(tolower(substr(reason, 1, 1)), \n                           substr(reason, 2, nchar(reason))),\n                    NA)\n  )\n\ndiff_df_raw <- paper_id |> map_dfr(function(paper_id) {\n  res <- all_geminis |> filter(id == paper_id) |> group_split(paper)\n  expand.grid(seq(1, 5, 1), seq(1, 5, 1)) |>\n    filter(Var1 < Var2) |>\n    rowwise() |>\n    mutate(\n      cmpr_obj = list(waldo::compare(\n        res[[Var1]] |> select(reason, decision),\n        res[[Var2]] |> select(reason, decision))), \n      ll = length(cmpr_obj),\n      paper = paper_id, \n      same_n = nrow(res[[Var1]]) == nrow(res[[Var2]]))\n})\n\nllm_temp_df <- diff_df_raw |> \n  mutate(n_diff = NA) |> \n  mutate(n_diff = ifelse(ll == 2, \n                         str_count(cmpr_obj[[2]], \"\\033\\\\[33m\") + \n                           str_count(cmpr_obj[[2]], \"\\033\\\\[32m\")/2, \n                         n_diff),\n         n_diff = ifelse(ll == 3, \n                         str_count(cmpr_obj[[2]], \"\\033\\\\[33m\") + \n                           str_count(cmpr_obj[[2]], \"\\033\\\\[32m\")/2 + \n                           str_count(cmpr_obj[[3]], \"\\033\\\\[33m\") + \n                           str_count(cmpr_obj[[3]], \"\\033\\\\[32m\")/2, \n                         n_diff),\n         n_diff = ifelse(ll == 0, 0, n_diff)) |> \n  ungroup() |> \n  select(-cmpr_obj)\n#save(all_geminis, file = here::here(\"data/all_geminis.rda\"))\n#save(llm_temp_df, file = here::here(\"data/llm_temp_df.rda\"))\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code .hidden}\nall_same_length_papers <- llm_temp_df |>\n  group_by(paper) |> \n  reframe(a = unique(same_n)) |> \n  count(paper) |> \n  filter(n == 1) |> \n  pull(paper)\n\ntbl <- llm_temp_df |> \n  filter(same_n) |> \n  count(n_diff) |> \n  mutate(prop = n / sum(n) * 100) \n```\n:::\n\n\nFor our text extraction task, we test the reproducibility of Gemini (`gemini-2.0-flash`) by repeating the text extraction task 5 times for each of the 62 papers. For each of the 31 papers, five runs yield $5 \\times 4 /2 = 10$ pairwise comparisons per field and including both the “reason” and “decision” fields results in a total of $31 \\times 10 \\times 2 = 620$ pairs. We exclude the pairs that have different number of decisions since it would require manually align the decision to compare and this left us with 449 out of 620 (72%) pairwise comparisons. @tbl-gemini-1 shows an example of such comparison in @andersen2008, where all the four reasons are identical among the two runs, hence a zero number of difference.\n\n\n::: {#tbl-gemini-1 .cell layout-align=\"center\" tbl-cap='An example of comparing the text extraction in decisions in Andersen 2008.'}\n\n```{.r .cell-code .hidden}\nres <-  all_geminis |> \n    filter(str_detect(paper, \"andersen2008size\")) |>\n    group_split(paper)\n\ntibble(Variable = res[[2]]$variable, \n       Run1 = res[[2]]$decision, \n       Run2 = res[[3]]$decision) |> \n  filter(!row_number() %in% c(1, 2)) |> \n  knitr::kable()\n```\n\n::: {.cell-output-display}\n\n\n|Variable              |Run1                  |Run2                  |\n|:---------------------|:---------------------|:---------------------|\n|NCtot                 |6day average (lag 05) |6day average (lag 05) |\n|calendar time         |3 4 or 5 dfyear       |3 4 or 5 dfyear       |\n|dew-point temperature |4 or 5 df             |4 or 5 df             |\n|temperature           |4 or 5 df             |4 or 5 df             |\n\n\n:::\n:::\n\n\n@tbl-gemini-2 summarizes the number of differences observed in each pairwise comparison. Among all comparisons, 80% produce the identical text in reason and decision. The discrepancies come from the following reasons:\n\n-   Gemini extracted different length for the same decision, e.g. in @kan2007, some runs may extract \"singleday lag models underestimate the cumulative effect of pollutants on mortality 2day moving average **of current and previous day concentrations** (lag=01)\", while others extract \"singleday lag models underestimate the cumulative effect of pollutants on mortality 2day moving average (lag=01)\". Similarity, for decisions, some runs may yield \"10 df for total mortality\", while other runs yield \"10 df\". Similar extraction appears in @breitner2009.\n-   Gemini fails to extract reasons in some runs but not others, e.g. in @burnett1998, the first run generates NAs in the reasons, but the remaining four runs are identical. In @ueda2009 and @castillejos2000 , runs 1 and 5 fail to extract the reasons and produce the same incomplete version, whereas runs 2, 3, and 4 produce accurate versions with reasons populated.\n\n\n::: {#tbl-gemini-2 .cell layout-align=\"center\" tbl-cap='Number of differences in the reason and decision fields across Gemini runs for papers with consistent number of decisions across runs.'}\n\n```{.r .cell-code .hidden}\nload(here::here(\"data/llm_temp_df.rda\"))\ntibble(n_diff = 0:11) |> \n  left_join(tbl) |> \n  replace_na(list(n = 0, prop = 0)) |> \n  rename(`Num. of  difference` = n_diff, Count = n, `Proportion (%)` = prop) |> \n  janitor::adorn_totals() |> \n  knitr::kable(digits = 2)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nJoining with `by = join_by(n_diff)`\n```\n\n\n:::\n\n::: {.cell-output-display}\n\n\n|Num. of  difference | Count| Proportion (%)|\n|:-------------------|-----:|--------------:|\n|0                   |   358|          79.73|\n|1                   |    12|           2.67|\n|2                   |     8|           1.78|\n|3                   |     0|           0.00|\n|4                   |    24|           5.35|\n|5                   |    12|           2.67|\n|6                   |     3|           0.67|\n|7                   |     0|           0.00|\n|8                   |    10|           2.23|\n|9                   |     6|           1.34|\n|10                  |    10|           2.23|\n|11                  |     6|           1.34|\n|Total               |   449|         100.00|\n\n\n:::\n:::\n\n\n## LLM models {#sec-llm-models}\n\nReading text from PDF document requires Optical Character Recognition (OCR) to convert images into machine-readable text, which currently is only supported by Antropic Claude (`claude-3-7-sonnet-latest`) and Google Gemini (`gemini-2.0-flash`).\n\nWe compare the number of decisions extracted by Claude and Gemini across all 62 papers in @fig-claude-gemini. Each point represents a paper, with the x- and y-axes showing the number of decisions extracted by Claude and Gemini, respectively. The dashed 1:1 line marks where both models extract the same number of decisions. Most points fall below this line, indicating that Claude extracts more decisions -- often from data pre-processing or secondary data analysis steps requiring more manual validation -- whereas Gemini focuses more on modelling choices relevant to our analysis. Some of these decisions captured by Claude are\n\n-   the definition of \"cold day\" and \"hot day\" indicators in @dockery1992 (\"defined at the 5th/ 95th percentile\"),\n-   the choice to summarize $\\text{NO}_2$, $\\text{O}_3$, and $\\text{SO}_2$ using a \"24 hr average on variable\" in @huang2009, and\n-   the definition of black smoke and in @katsouyanni2001 for secondary analysis (\"restrict to days with BS concentrations below 150 $\\mu g/m^2$\").\n\nGemini sometimes also include irrelevant decisions, such as in @mar2000, where secondary analysis choices like \"0-4 lag days\" for air pollution exposure variables (CO, EC, $\\text{K}_S$, $\\text{NO}_2$, $\\text{O}_3$, OC, Pb, S, $\\text{SO}_2$, TC, Zn) are captured. However, these cases are less frequent, resulting in outputs with less noise overall.\n\nFor both Claude and Gemini, we find they fail to link the general term \"weather variables\" to the specific weather variables. For example Gemini misses this link in @dockery1992 and @burnett2004, while Claude does so in @dockery1992 and @katsouyanni2001. Although our prompt specified that some decisions may require linking information across sentences and paragraphs to identify the correct variable, this instruction doesn't appear to be applied consistently.\n\n\n::: {#cell-fig-claude-gemini .cell layout-align=\"center\"}\n\n```{.r .cell-code .hidden}\nclaude_gemini <- claude_df |> \n  mutate(paper = str_remove(paper, \"-claude-1\")) |>\n  group_by(paper) |> \n  count(paper) |> \n  left_join(gemini_df |> \n           mutate(paper = str_remove(paper, \"-gemini-1\")) |>\n             group_by(paper) |> \n             count(paper), by = \"paper\") |> \n  rename(claude = n.x, gemini = n.y)\n\nclaude_gemini |> \n  ggplot(aes(x = claude, y = gemini)) + \n  geom_label(data = claude_gemini |> \n               mutate(diff = abs(claude - gemini)) |> filter(diff >= 5),\n            aes(label = paper), nudge_y = -0.7, nudge_x = 2) + \n   geom_point(data = claude_gemini |> \n               mutate(diff = abs(claude - gemini)) |> filter(diff >= 5)) + \n  geom_jitter(data = claude_gemini |> \n               mutate(diff = abs(claude - gemini)) |> filter(diff < 5),\n              width = 0.2, height = 0.2) + \n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\") +\n  #geom_abline(slope = 1, intercept = -4, color = 'purple') +\n  #geom_abline(slope = 1, intercept = 4, color = \"purple\") +\n  theme_bw() + \n  theme(aspect.ratio = 1, panel.grid.minor = element_blank()) + \n  xlab(\"Num. of decisions extracted by Claude\") + \n  ylab(\"Num. of decisions extracted by Gemini\") + \n  xlim(0, 20) + \n  ylim(0, 20)\n```\n:::\n\n\n## Text model {#sec-text-model}\n\nWe have conducted sensitivity analysis on the text model for obtaining the decision similarity score from the Gemini outputs. The tested language models tested include\n\n1)  BERT by Google [@devlin2019],\n2)  RoBERTa by Facebook AI [@liu], trained on a larger dataset (160GB v.s. BERT's 15GB),\n3)  XLNnet by Google Brain [@yang], and\n\ntwo domain-trained BERT models:\n\n4)  sciBERT [@beltagy2019], trained on scientific literature, and\n5)  bioBERT [@lee2020], trained on PubMed and PMC data.\n\n@fig-text-density presents the distribution of the decision similarity (left) and paper similarity (right) for each text model. At decision level, the BERT model produces the widest variation across all five models, while the similarity scores from XLNet are all close to 1. These scores are not comparable across models since the difference of the underlying transformer architecture. However, the paper similarity scores from each model are comparable and @fig-text-mds shows the multi-dimensional scaling (MDS) of the paper similarity scores from each text model: all showing a similar clustering pattern of the three main smoothing methods.\n\n\n::: {#cell-fig-text-density .cell layout-align=\"center\"}\n\n```{.r .cell-code .hidden}\nmodels <- c(\"bert-base-uncased\", \"roberta-base\", \"xlnet-base-cased\", \n           \"allenai/scibert_scivocab_uncased\", \"dmis-lab/biobert-large-cased-v1.1-squad\")\nmodels_df <- tibble(id = 1:5, models = models, name = c(\"BERT\", \"RoBERTa\", \"XLNet\", \"SciBERT\", \"BioBERT\"))\n\np1 <- text_sensitivity_df |> \n  filter(!str_detect(decision, \"method\")) |> \n  left_join(models_df) |>\n  ggplot(aes(x = dist, fill = name)) + \n  geom_density(alpha = 0.3) + \n  facet_wrap(vars(name), ncol = 1, scales = \"free_y\") + \n  scale_x_continuous(breaks = seq(0.2, 1, 0.1)) + \n  xlab(\"Decision similarity scores\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nJoining with `by = join_by(id, models)`\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\ntext_distance_df <- text_sensitivity_decision_df |> \n  nest(data = -id) |> \n  mutate(id = as.numeric(id)) |> \n  rowwise() |> \n  mutate(score = list(calc_paper_similarity(data))) |> \n  unnest(score) |> \n  select(-data) |> \n  left_join(models_df)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nJoining with `by = join_by(id)`\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\np2 <- text_distance_df |> \n  ggplot(aes(x = similarity, fill = name)) + \n  geom_density(alpha = 0.3) + \n  facet_wrap(vars(name), ncol = 1) + \n  xlab(\"Paper similarity scores\")\n\n(p1 | p2) + plot_layout(guides = 'collect') &\n  theme_bw() + \n  theme(legend.position = 'bottom') \n```\n\n::: {.cell-output-display}\n![Distribution of decision similarity (left) and paper similarity (right) scores for five different text models (BERT, BioBERT, RoBERTa, SciBERT, and XLNet). The default language model, BERT, produces the widest variation across the five models, while the similarity scores form XLNet are all close to 1. The model BioBERT, RoBERTa, and SciBERT yield decision similar scores mostly between 0.7 to 1.](index_files/figure-pdf/fig-text-density-1.pdf){#fig-text-density fig-align='center' fig-pos='H'}\n:::\n:::\n\n\n\n::: {#cell-fig-text-mds .cell layout-align=\"center\"}\n\n```{.r .cell-code .hidden}\nmds_df <- text_distance_df |> \n  filter(!paper1 %in% bad & !paper2 %in% bad) |> \n  group_split(id) |> \n  map_dfr(run_mds, .id = \"id\") |> \n  mutate(id = as.numeric(id)) |> \n  left_join(method_df, by = c(\"paper\" = \"paper\")) |> \n  left_join(models_df) \n\nmds_df |> ggplot(aes(x = V1, y = V2, gorup = method)) + \n  geom_point(aes(color = method)) +\n  ggforce::geom_mark_hull(concavity = 5, aes(color = method), \n                          expand = unit(2.2, \"mm\")) + \n  facet_wrap(vars(name)) + \n  theme_bw() + \n  theme(aspect.ratio = 1, legend.position = \"bottom\")  \n```\n:::\n\n\n# Discussion {#sec-discussion}\n\n-   Only prompting engineering is used to extract decisions from the literature. We expect that fine-tuning the model on statistical or domain-specific literature to yield more robust performance on the same document, though it would require substantially more training effort.\n\n-   people from the NYU-LMU workshop are interested to have code script attached as well because people can do one thing in the script but report another in the paper - it would be interesting to compare the paper and the script with some syntax extraction.\n\n-   Spatial decisions are generally not well captured because it often conducted uniformly as estimating the city individually to accommodate city heterogeneity. Some papers only consider a handful of cities, while in larger studies the individual city effects are then pooled together using random effect.\n\n-   Validation of the output:\n\nthe nature of the task: Our task involve a reasoning component in that it requires casual reasoning to identify the decisions made by the authors, and its justification/ rationale, rather than purely summarizing the text through pattern-matching.\n\n-   some decisions are more varied than others and can be reported by different ways. e.g. the most common way to report the smoothing parameter for time is the number of knots/ degree of freedom per year. While authors may report this number in different ways, i.e. \"every 30 days\". A secondary processing with LLM may be useful to align the raw text into the same reporting unit.s\n\n- the variation of parameters people use can help to identify parameter that needs a separate sensitivity analysis\n\n# References {.unnumbered}\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}