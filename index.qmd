---
title: Analysing decisions in data analysis
authors:
  - name: H. Sherry Zhang
    affiliation: University of Texas at Austin
    corresponding: true
  - name: Roger D. Peng
    affiliation: University of Texas at Austin
bibliography: references.bib
link-citations: true
number-sections: true
---

# Introduction

In this work, we design a tabular format to record the choices made by analysts during data analysis. Using large language models, we automatically extract these choices from a set of research papers focused on specific topics, e.g. air pollution modelling. This allows us to analyze these choices as data – tracking how they've changed over time or query the possible methodologies used in similar studies. We also introduce a workflow to cluster paper based on decision similarity, using both the decisions themselves and the justifications authors provide for their choices.

# Background

Data analysis as an complicated, iterative process to make sense \[ref\] of the data collected. The iterative process of formulating hypothesis @jun2022.

Choices are made at nearly every stage of data analysis, ranging from variable pre-processing variables, variable and lag selection in model formulation, to the specification of smoothing parameter during model construction. These possible choices contribute to what @gelman2014 describe as the "garden of forking paths". These choices can introduce substantial variability in results, which has been demonstrated in many-analyst experiments, where independent teams analyzing the same dataset to answer a pre-defined research question often arrive at markedly different conclusions. A prominent example is @silberzahn2018 where researchers reported a wide range of point estimates and 95% confidence intervals for the effect of soccer players’ skin tone on the number of red cards awarded by referees (odds ratio from 0.89 to 2.93). Similar findings have emerged in other domains, including structural equation modeling [@sarstedt2024], applied microeconomics [@huntington-klein2021], neuroimaging [@botvinik-nezer2020], and ecology and evolutionary biology [@gould2025].

Given this nature that a wide range of choices can be justified, there has been the long discussion of p-hacking and other misuse of statistics in practical data analysis in publication. \[more on p-hacking and reseracher's degree of freedom\]. Some proposed guidelines and recommendation to overcome this through pre-registration.

-   pre-registration
-   @wicherts2016degrees provides a checklist of researcher degrees of freedom to combat the "garden of forking paths" problem
-   false-positive psychology suggests 6 guidelines for reporting data analysis to prevent false-positive rate

Another line of work focuses on developing software tools to support analysts in making more informed decisions. For example, the `Tisane` package [@jun2022] integrates conceptual ideas, such as DAGs, and modelling structure (group/ cluster/ hierarchical structure), to assist junior researchers in specifying GLM and GLMM model. The `DeclareDesign` package [@blair2019] introduces the MIDA framework for researchers to declare, diagnose, and redesign their analyses to produce a distribution of the statistic of interest. This approach has been applied in randomized controlled trial [@bishop2024] . The `multiverse` package facilitates the specification and execution of multiple parallel choices for sensitivity analysis, allowing researchers to systematically explore how different choices affect results and to report the range of plausible outcomes that arise from alternative analytic paths.

-   Study decisions in data analysis:

    -   an interview/ participatory method: @simson, many others
    -   (automated) visualization of decisions made in data analysis:
        -   datamation [@pu2023],
        -   @liu2020paths uses Analytic Decision Graphs (ADG) to represent high-level decision process in data analysis.
        -   [Urania: Visualizing Data Analysis Pipelines for Natural Language-Based Data Exploration](https://arxiv.org/pdf/2306.07760)

# Construct decision databases

## Recording decisions in data analysis

-   give example from extracting decision from sentences of a paper
-   adapt from the tidy data principle [@tidydata], each row is a decision @wickham2014\
-   some decisions are related to how the variable is estimated spatially and temporally
-   model level decisions on how the model is estimated spatially (for multi-site analyses) and/or temporally (different treatments for years or seasons)
-   sometimes the decisions are not explicitly stated in the paper (use AIC to choose the degree of freedom in a smoothing spline)
-   sometimes the reason is not explicitly stated (e.g., why 3 degree of freedom)

A hypothetical database of decisions may look as follows:

| Paper | ID | Model | variable | method | parameter | type | reason | decision |
|--------|--------|--------|--------|--------|--------|--------|--------|--------|
| ostro | 1 | Poisson regression | temperature | smoothing spline | degree of freedom | parameter | NA | 3 degree of freedom |
| ostro | 2 | Poisson regression | temperature | smoothing spline | degree of freedom | temporal | NA | 1-day lag |
| ostro | 3 | Poisson regression | relative humidity | LOESS | smoothing parameter | parameter | to minimize Akaike's Information Criterion | NA |
| ostro | 4 | Poisson regression | model | NA | NA | spatial | to account for variation among cities | separate regression models fit in each city |

## Austomatic reading of literature with LLM

-   We use LLM to automatic read the paper through the `ellmer` package [@ellmer] and manually review the decision outputs. Both Antropic Claude and Google Gemini accept pdf inputs and we choose Claude. The prompt used to finetune the Claude LLM is available in the appendix.

## Review the LLM output

(the shiny app)

-   screenshot of the interface
-   The current application includes three actions:
    -   modify a row (`dplyr::mutate(xxx = ifelse(CONDITION, "yyy" , xxx))`),
    -   delete unrelated decisions (`dplyr::filter(!(CONDITION))`), and
    -   manually add a decision (`dplyr::bind_rows()`)
-   All the actions will generate the corresponding codes.
-   The download button will download the modified decision database as a csv file

### Decision quality summary

# Calculate paper similarity

-   pre-processing
    -   standardize statistical methods its corresponding parameters (LOESS, smoothing spline, etc)
    -   group variables into broader categories: time, temperature, humidity, PM
-   identify the most frequent analysis decisions across papers
-   retain only papers that report more than x such decisions
-   measure similarity between decisions and their justificaiton using NLP
    -   word embedding with attention mechanism, instead of bag of word,
    -   specific NLP models (default to `bert-base-uncased`), aggregation methods from word to text
-   compute paper similarity score for each paper pair by aggregating decision-level compoarisons
    -   check/ report on the number of decisions compared in each paper pair
-   similarity score can serve as the distance matrix to cluster papers by their similarity on decision choices

# Applications

## Air pollution mortality modelling

-   look at for one type of decision (time) - what are the choices made by different papers
-   look at whether decisions changes across time
-   Visualize the decision database: apply clustering algorithm and visualize the database through `sigma.js`

## Species distribution modelling

# Discussion

-   Only prompting engineering is used to extract decisions from the literature. We expect that fine-tuning the model on statistical or domain-specific literature to yield more robust performance on the same document, though it would require substantially more training effort.

# Reference
